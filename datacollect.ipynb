{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66b6e31f-9bc7-448e-b47d-803237edbd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          level_0       Close Symbol Security  GICS Sector\n",
      "Date                                                                      \n",
      "2019-01-02 00:00:00-05:00     MMM  153.602448    MMM       3M  Industrials\n",
      "2019-01-03 00:00:00-05:00     MMM  147.818726    MMM       3M  Industrials\n",
      "2019-01-04 00:00:00-05:00     MMM  153.900055    MMM       3M  Industrials\n",
      "2019-01-07 00:00:00-05:00     MMM  153.546112    MMM       3M  Industrials\n",
      "2019-01-08 00:00:00-05:00     MMM  154.189667    MMM       3M  Industrials\n",
      "...                           ...         ...    ...      ...          ...\n",
      "2020-10-07 00:00:00-04:00     MMM  142.362320    MMM       3M  Industrials\n",
      "2020-10-08 00:00:00-04:00     MMM  143.405533    MMM       3M  Industrials\n",
      "2020-10-09 00:00:00-04:00     MMM  144.765091    MMM       3M  Industrials\n",
      "2020-10-12 00:00:00-04:00     MMM  144.209274    MMM       3M  Industrials\n",
      "2020-10-13 00:00:00-04:00     MMM  142.482056    MMM       3M  Industrials\n",
      "\n",
      "[450 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>Close</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>153.602448</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>147.818726</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>153.900055</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>153.546112</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>154.189667</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>194.538773</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>195.057587</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.454422</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.713837</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.923355</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615162 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          level_0       Close Symbol Security  GICS Sector\n",
       "Date                                                                      \n",
       "2019-01-02 00:00:00-05:00     MMM  153.602448    MMM       3M  Industrials\n",
       "2019-01-03 00:00:00-05:00     MMM  147.818726    MMM       3M  Industrials\n",
       "2019-01-04 00:00:00-05:00     MMM  153.900055    MMM       3M  Industrials\n",
       "2019-01-07 00:00:00-05:00     MMM  153.546112    MMM       3M  Industrials\n",
       "2019-01-08 00:00:00-05:00     MMM  154.189667    MMM       3M  Industrials\n",
       "...                           ...         ...    ...      ...          ...\n",
       "2023-12-22 00:00:00-05:00     ZTS  194.538773    ZTS   Zoetis  Health Care\n",
       "2023-12-26 00:00:00-05:00     ZTS  195.057587    ZTS   Zoetis  Health Care\n",
       "2023-12-27 00:00:00-05:00     ZTS  196.454422    ZTS   Zoetis  Health Care\n",
       "2023-12-28 00:00:00-05:00     ZTS  196.713837    ZTS   Zoetis  Health Care\n",
       "2023-12-29 00:00:00-05:00     ZTS  196.923355    ZTS   Zoetis  Health Care\n",
       "\n",
       "[615162 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import yfinance as yf \n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx \n",
    "import numpy as np \n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "#read wikipedia S&P500 table into PD dataframe \n",
    "df_sp500 = pd.read_html(url)[0][['Symbol', 'Security', 'GICS Sector']] \n",
    "#ticker DF \n",
    "sp500_tickers = df_sp500['Symbol'].tolist() \n",
    "\n",
    "#read changes table into DF \n",
    "#sp500_changes = pd.read_html(url)[1]\n",
    "#problematic \n",
    "# drop rows where at least one element missing\n",
    "#changes = df_changes[['Date', 'Added', 'Removed']].dropna() \n",
    "#filter out reasons column \n",
    "#changes = changes[~changes['Date'].str.contains('Reason')]\n",
    "#filter out note column \n",
    "#changes = changes[~changes['Date'].str.contains('Note')] \n",
    "\n",
    "#leaving these fuckers out (Berkshire Hathaway - 2010, Brown-Forman - 1982, AirBNB - 2023....so on)\n",
    "#issues: these have not been in the dataset for the full time period (1258 days) so i need to leave them out until ifigure something out \n",
    "exclude = ['BRK.B', 'BF.B', 'ABNB', 'CARR', 'CEG', 'CTVA', 'DOW', 'FOXA', 'FOX', 'GEHC', 'KVUE', 'OTIS', 'UBER', 'VLTO'] \n",
    "sp500_tickers = [ticker for ticker in sp500_tickers if ticker not in exclude]\n",
    "\n",
    "#dict for individual stock DF storage \n",
    "stockdataframes = {} \n",
    "\n",
    "start_dte = \"2019-01-01\"\n",
    "end_dte = \"2023-12-31\"\n",
    "\n",
    "#ADD INCLUSION AND EXCLUSION DATE AND FILTER BY THAT FOR NEWER STOCKS AND REMOVED ONES \n",
    "\n",
    "#iterate through all tickers+ get historical data \n",
    "for ticker in sp500_tickers: \n",
    "    #added = row['Added'] \n",
    "    #removed = row['Removed'] \n",
    "    \n",
    "    try:\n",
    "        stock = yf.Ticker(ticker) \n",
    "        stock_df = stock.history(start=start_dte, end=end_dte)[['Close']]\n",
    "        \n",
    "        #debug \n",
    "        #print(f\"Debug - Ticker: {ticker}, DataFrame shape: {stock_df.shape}\")\n",
    "        \n",
    "        #merge with wiki data - check if not empty first\n",
    "        if 'Close' in stock_df.columns and not stock_df.empty: \n",
    "            stock_df['Symbol'] = ticker\n",
    "            stock_df['Security'] = df_sp500[df_sp500['Symbol'] == ticker]['Security'].iloc[0]\n",
    "            stock_df['GICS Sector'] = df_sp500[df_sp500['Symbol'] == ticker]['GICS Sector'].iloc[0]\n",
    "            #merged_stock_df = pd.merge(stock_df, df_sp500[df_sp500['Symbol'] == ticker], left_index=True, right_index=True)\n",
    "        \n",
    "            #store merged df in dictionary \n",
    "            stockdataframes[ticker] = stock_df #used o be merged_stock_dataframe\n",
    "        \n",
    "            #print(f\"Data fetched for {ticker}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {ticker}: {e}\")\n",
    "    except Exception as e: \n",
    "        print(f\"Failed to fetch data for {ticker}: {e}\")\n",
    "\n",
    "#merge all stock dfs into one \n",
    "full_df = pd.concat(stockdataframes.values(), keys=stockdataframes.keys())\n",
    "\n",
    "full_df = full_df.reset_index(level=0) \n",
    "\n",
    "#ptiny \n",
    "print(full_df.head(450)) \n",
    "display(full_df) \n",
    "full_df.to_csv('SP500.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1689b6d-72b6-48cb-8c7f-9b0ec887da4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    2019-01-02 00:00:00-05:00\n",
      "1    2019-01-03 00:00:00-05:00\n",
      "2    2019-01-04 00:00:00-05:00\n",
      "3    2019-01-07 00:00:00-05:00\n",
      "4    2019-01-08 00:00:00-05:00\n",
      "Name: Date, dtype: object\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can only use .dt accessor with datetimelike values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lastday \n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#func call to each row \u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m lastdays \u001b[38;5;241m=\u001b[39m [last_trade_day(year, month) \u001b[38;5;28;01mfor\u001b[39;00m year, month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39myear, full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth)]\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#add accurate last days to df \u001b[39;00m\n\u001b[1;32m     31\u001b[0m full_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast_Trade_Day\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m lastdays \n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:5989\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5983\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[1;32m   5984\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[1;32m   5985\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[1;32m   5986\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[1;32m   5987\u001b[0m ):\n\u001b[1;32m   5988\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[0;32m-> 5989\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/accessor.py:224\u001b[0m, in \u001b[0;36mCachedAccessor.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor\n\u001b[0;32m--> 224\u001b[0m accessor_obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessor(obj)\n\u001b[1;32m    225\u001b[0m \u001b[38;5;66;03m# Replace the property with the accessor object. Inspired by:\u001b[39;00m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;66;03m# https://www.pydanny.com/cached-property.html\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# We need to use object.__setattr__ because we overwrite __setattr__ on\u001b[39;00m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# NDFrame\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_name, accessor_obj)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/accessors.py:580\u001b[0m, in \u001b[0;36mCombinedDatetimelikeProperties.__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_period_dtype(data\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m PeriodProperties(data, orig)\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only use .dt accessor with datetimelike values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
     ]
    }
   ],
   "source": [
    "#fixing monthly data missing issue \n",
    "import pandas as pd \n",
    "\n",
    "filepath = 'SP500.csv' \n",
    "full_df = pd.read_csv(filepath) \n",
    "\n",
    "# Convert date to datetime\n",
    "full_df['Date'] = pd.to_datetime(full_df['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaT (Not a Time) values\n",
    "full_df = full_df.dropna(subset=['Date'])\n",
    "\n",
    "# Print the data type of the 'Date' column to ensure it's datetime-like\n",
    "print(full_df['Date'].dtype)\n",
    "print(full_df['Date'].head())\n",
    "\n",
    "#non_date_values = full_df['Date'][pd.to_datetime(full_df['Date'], errors='coerce').isna()]\n",
    "#print(non_date_values)\n",
    "\n",
    "#find last trade days \n",
    "def last_trade_day(year, month): \n",
    "    lastday = pd.Timestamp(year, month, 1) + pd.offsets.MonthEnd(0) \n",
    "    while lastday.weekday() >= 5: #weekend days \n",
    "        lastday -= pd.Timedelta(days=1)\n",
    "    return lastday \n",
    "\n",
    "#func call to each row \n",
    "lastdays = [last_trade_day(year, month) for year, month in zip(full_df['Date'].dt.year, full_df['Date'].dt.month)]\n",
    "\n",
    "#add accurate last days to df \n",
    "full_df['Last_Trade_Day'] = lastdays \n",
    "\n",
    "#filtering \n",
    "last_day_df = full_df[full_df['Date'] == full_df['Last_Trading_Day']]\n",
    "\n",
    "#reset index \n",
    "\n",
    "#print(len(last_day_df))\n",
    "#print(last_day_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dc5f72-1c02-40f3-9290-839fc23b40ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "monthly_df = full_df.resample('M').last() \n",
    "\n",
    "# Calculate Spearman correlation coefficient\n",
    "corr_matrix = monthly_df.pivot(columns='Symbol', values='Close').pct_change().corr(method='spearman').dropna()\n",
    "\n",
    "#create graph \n",
    "G = nx.Graph() \n",
    "\n",
    "for stock in sp500_tickers: \n",
    "    G.add_node(stock) \n",
    "    \n",
    "#add links \n",
    "for i in range(len(sp500_tickers)): \n",
    "    for j in range(i + 1, len(sp500_tickers)):\n",
    "        stock1 = sp500_tickers[i]\n",
    "        stock2 = sp500_tickers[j]\n",
    "        \n",
    "        # Check if the stock symbols are present in the correlation matrix\n",
    "        if stock1 in corr_matrix.index and stock2 in corr_matrix.columns:\n",
    "            correlation_coefficient = corr_matrix.loc[stock1, stock2]\n",
    "            if not np.isnan(correlation_coefficient):\n",
    "                G.add_edge(stock1, stock2, weight=correlation_coefficient)\n",
    "\n",
    "#visualization \n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "# Draw only edges with significant correlation\n",
    "edges = [(source, target) for source, target, data in G.edges(data=True) if abs(data['weight']) > 0.5]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=30)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color='gray')\n",
    "\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97870d85-4565-4744-8405-904cc9ca9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REF \n",
    "#import pandas as pd \n",
    "#import yfinance as yf \n",
    "\n",
    "#url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "#read tables into PD dataframe \n",
    "#dfs = pd.read_html(url) \n",
    "\n",
    "#get first table (index 0) + first 3 cols \n",
    "#df = dfs[0].iloc[:, :3] \n",
    "#print(df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
