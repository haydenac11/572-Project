{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b6e31f-9bc7-448e-b47d-803237edbd0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          level_0       Close Symbol Security  GICS Sector\n",
      "Date                                                                      \n",
      "2019-01-02 00:00:00-05:00     MMM  153.602432    MMM       3M  Industrials\n",
      "2019-01-03 00:00:00-05:00     MMM  147.818665    MMM       3M  Industrials\n",
      "2019-01-04 00:00:00-05:00     MMM  153.900070    MMM       3M  Industrials\n",
      "2019-01-07 00:00:00-05:00     MMM  153.546112    MMM       3M  Industrials\n",
      "2019-01-08 00:00:00-05:00     MMM  154.189621    MMM       3M  Industrials\n",
      "...                           ...         ...    ...      ...          ...\n",
      "2020-10-07 00:00:00-04:00     MMM  142.362335    MMM       3M  Industrials\n",
      "2020-10-08 00:00:00-04:00     MMM  143.405533    MMM       3M  Industrials\n",
      "2020-10-09 00:00:00-04:00     MMM  144.765091    MMM       3M  Industrials\n",
      "2020-10-12 00:00:00-04:00     MMM  144.209305    MMM       3M  Industrials\n",
      "2020-10-13 00:00:00-04:00     MMM  142.482040    MMM       3M  Industrials\n",
      "\n",
      "[450 rows x 5 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>Close</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Security</th>\n",
       "      <th>GICS Sector</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-02 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>153.602432</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>147.818665</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-04 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>153.900070</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-07 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>153.546112</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-08 00:00:00-05:00</th>\n",
       "      <td>MMM</td>\n",
       "      <td>154.189621</td>\n",
       "      <td>MMM</td>\n",
       "      <td>3M</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-22 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>194.538773</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-26 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>195.057587</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-27 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.454422</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-28 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.713837</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-12-29 00:00:00-05:00</th>\n",
       "      <td>ZTS</td>\n",
       "      <td>196.923355</td>\n",
       "      <td>ZTS</td>\n",
       "      <td>Zoetis</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>615162 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          level_0       Close Symbol Security  GICS Sector\n",
       "Date                                                                      \n",
       "2019-01-02 00:00:00-05:00     MMM  153.602432    MMM       3M  Industrials\n",
       "2019-01-03 00:00:00-05:00     MMM  147.818665    MMM       3M  Industrials\n",
       "2019-01-04 00:00:00-05:00     MMM  153.900070    MMM       3M  Industrials\n",
       "2019-01-07 00:00:00-05:00     MMM  153.546112    MMM       3M  Industrials\n",
       "2019-01-08 00:00:00-05:00     MMM  154.189621    MMM       3M  Industrials\n",
       "...                           ...         ...    ...      ...          ...\n",
       "2023-12-22 00:00:00-05:00     ZTS  194.538773    ZTS   Zoetis  Health Care\n",
       "2023-12-26 00:00:00-05:00     ZTS  195.057587    ZTS   Zoetis  Health Care\n",
       "2023-12-27 00:00:00-05:00     ZTS  196.454422    ZTS   Zoetis  Health Care\n",
       "2023-12-28 00:00:00-05:00     ZTS  196.713837    ZTS   Zoetis  Health Care\n",
       "2023-12-29 00:00:00-05:00     ZTS  196.923355    ZTS   Zoetis  Health Care\n",
       "\n",
       "[615162 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import yfinance as yf \n",
    "from scipy.stats import spearmanr\n",
    "import networkx as nx \n",
    "import numpy as np \n",
    "\n",
    "url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "#read wikipedia S&P500 table into PD dataframe \n",
    "df_sp500 = pd.read_html(url)[0][['Symbol', 'Security', 'GICS Sector']] \n",
    "#ticker DF \n",
    "sp500_tickers = df_sp500['Symbol'].tolist() \n",
    "\n",
    "#read changes table into DF \n",
    "#sp500_changes = pd.read_html(url)[1]\n",
    "#problematic \n",
    "# drop rows where at least one element missing\n",
    "#changes = df_changes[['Date', 'Added', 'Removed']].dropna() \n",
    "#filter out reasons column \n",
    "#changes = changes[~changes['Date'].str.contains('Reason')]\n",
    "#filter out note column \n",
    "#changes = changes[~changes['Date'].str.contains('Note')] \n",
    "\n",
    "#leaving these fuckers out (Berkshire Hathaway - 2010, Brown-Forman - 1982, AirBNB - 2023....so on)\n",
    "#issues: these have not been in the dataset for the full time period (1258 days) so i need to leave them out until ifigure something out \n",
    "exclude = ['BRK.B', 'BF.B', 'ABNB', 'CARR', 'CEG', 'CTVA', 'DOW', 'FOXA', 'FOX', 'GEHC', 'KVUE', 'OTIS', 'UBER', 'VLTO'] \n",
    "sp500_tickers = [ticker for ticker in sp500_tickers if ticker not in exclude]\n",
    "\n",
    "#dict for individual stock DF storage \n",
    "stockdataframes = {} \n",
    "\n",
    "start_dte = \"2019-01-01\"\n",
    "end_dte = \"2023-12-31\"\n",
    "\n",
    "#ADD INCLUSION AND EXCLUSION DATE AND FILTER BY THAT FOR NEWER STOCKS AND REMOVED ONES \n",
    "\n",
    "#iterate through all tickers+ get historical data \n",
    "for ticker in sp500_tickers: \n",
    "    #added = row['Added'] \n",
    "    #removed = row['Removed'] \n",
    "    \n",
    "    try:\n",
    "        stock = yf.Ticker(ticker) \n",
    "        stock_df = stock.history(start=start_dte, end=end_dte)[['Close']]\n",
    "        \n",
    "        #debug \n",
    "        #print(f\"Debug - Ticker: {ticker}, DataFrame shape: {stock_df.shape}\")\n",
    "        \n",
    "        #merge with wiki data - check if not empty first\n",
    "        if 'Close' in stock_df.columns and not stock_df.empty: \n",
    "            stock_df['Symbol'] = ticker\n",
    "            stock_df['Security'] = df_sp500[df_sp500['Symbol'] == ticker]['Security'].iloc[0]\n",
    "            stock_df['GICS Sector'] = df_sp500[df_sp500['Symbol'] == ticker]['GICS Sector'].iloc[0]\n",
    "            #merged_stock_df = pd.merge(stock_df, df_sp500[df_sp500['Symbol'] == ticker], left_index=True, right_index=True)\n",
    "        \n",
    "            #store merged df in dictionary \n",
    "            stockdataframes[ticker] = stock_df #used o be merged_stock_dataframe\n",
    "        \n",
    "            #print(f\"Data fetched for {ticker}\")\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {ticker}: {e}\")\n",
    "    except Exception as e: \n",
    "        print(f\"Failed to fetch data for {ticker}: {e}\")\n",
    "\n",
    "#merge all stock dfs into one \n",
    "full_df = pd.concat(stockdataframes.values(), keys=stockdataframes.keys())\n",
    "\n",
    "full_df = full_df.reset_index(level=0) \n",
    "\n",
    "#ptiny \n",
    "print(full_df.head(450)) \n",
    "display(full_df) \n",
    "#full_df.to_csv('SP500.csv', index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b502bab-77e0-43ad-a336-8ed415caa142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Granger causality between MMM and ZTS: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khushi/anaconda3/lib/python3.11/site-packages/statsmodels/tsa/stattools.py:1488: FutureWarning: verbose is deprecated since functions should not print results\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#granger causality \n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "def calculate_granger_causality(data1, data2, max_lag=1, significance_level=0.05):\n",
    "    # Perform Granger causality test\n",
    "    granger_result = grangercausalitytests(np.column_stack((data1, data2)), max_lag, verbose=False)\n",
    "    \n",
    "    # Extract p-values\n",
    "    p_values = [granger_result[i+1][0]['ssr_ftest'][1] for i in range(max_lag)]\n",
    "    \n",
    "    # Check if any p-value is below significance level\n",
    "    return any(p < significance_level for p in p_values)\n",
    "\n",
    "stocks_by_symbol = {} \n",
    "\n",
    "for symbol, data in full_df.groupby('Symbol'):\n",
    "    data.reset_index(inplace=True)\n",
    "    stocks_by_symbol[symbol] = data[['Date','Close']]   \n",
    "\n",
    "stock1_data = stocks_by_symbol['MMM']['Close']\n",
    "stock2_data = stocks_by_symbol['ZTS']['Close']\n",
    "\n",
    "# Calculate Granger causality\n",
    "granger_result = calculate_granger_causality(stock1_data, stock2_data, max_lag=1, significance_level=0.05)\n",
    "print(\"Granger causality between MMM and ZTS:\", granger_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85bfbe-8da8-40b1-8e4d-c77aa9a24ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1689b6d-72b6-48cb-8c7f-9b0ec887da4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0    2019-01-02 00:00:00-05:00\n",
      "1    2019-01-03 00:00:00-05:00\n",
      "2    2019-01-04 00:00:00-05:00\n",
      "3    2019-01-07 00:00:00-05:00\n",
      "4    2019-01-08 00:00:00-05:00\n",
      "Name: Date, dtype: object\n",
      "0\n",
      "Empty DataFrame\n",
      "Columns: [Date, level_0, Close, Symbol, Security, GICS Sector, Last_Trade_Day]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#fixing monthly data missing issue \n",
    "import pandas as pd \n",
    "\n",
    "filepath = 'SP500.csv' \n",
    "full_df = pd.read_csv(filepath) \n",
    "\n",
    "# Convert date to datetime\n",
    "full_df['Date'] = pd.to_datetime(full_df['Date'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaT (Not a Time) values\n",
    "full_df = full_df.dropna(subset=['Date'])\n",
    "\n",
    "# Print the data type of the 'Date' column to ensure it's datetime-like\n",
    "print(full_df['Date'].dtype)\n",
    "print(full_df['Date'].head())\n",
    "\n",
    "#non_date_values = full_df['Date'][pd.to_datetime(full_df['Date'], errors='coerce').isna()]\n",
    "#print(non_date_values)\n",
    "\n",
    "#find last trade days \n",
    "def last_trade_day(year, month): \n",
    "    lastday = pd.Timestamp(year, month, 1) + pd.offsets.MonthEnd(0) \n",
    "    while lastday.weekday() >= 5: #weekend days \n",
    "        lastday -= pd.Timedelta(days=1)\n",
    "    return lastday \n",
    "\n",
    "# Create a new column 'Last_Trade_Day' with accurate last trading days\n",
    "full_df['Last_Trade_Day'] = [last_trade_day(date.year, date.month) for date in full_df['Date']]\n",
    "\n",
    "# Filter rows where 'Date' equals 'Last_Trade_Day'\n",
    "last_day_df = full_df[full_df['Date'] == full_df['Last_Trade_Day']]\n",
    "\n",
    "# Reset index\n",
    "last_day_df = last_day_df.reset_index(drop=True)\n",
    "\n",
    "print(len(last_day_df))\n",
    "print(last_day_df.head())\n",
    "\n",
    "#func call to each row \n",
    "#lastdays = [last_trade_day(year, month) for year, month in zip(full_df['Date'].dt.year, full_df['Date'].dt.month)]\n",
    "#lastdays = [last_trade_day(date.year, date.month) for date in full_df['Last_Trade_Day']]\n",
    "\n",
    "#add accurate last days to df \n",
    "#full_df['Last_Trade_Day'] = lastdays \n",
    "\n",
    "#filtering \n",
    "#last_day_df = full_df[full_df['Date'] == full_df['Last_Trading_Day']]\n",
    "\n",
    "#reset index \n",
    "\n",
    "#print(len(last_day_df))\n",
    "#print(last_day_df.head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d0a508c-6544-4470-9d59-c565c3bcbfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dc5f72-1c02-40f3-9290-839fc23b40ab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "monthly_df = full_df.resample('M').last() \n",
    "\n",
    "# Calculate Spearman correlation coefficient\n",
    "corr_matrix = monthly_df.pivot(columns='Symbol', values='Close').pct_change().corr(method='spearman').dropna()\n",
    "\n",
    "#create graph \n",
    "G = nx.Graph() \n",
    "\n",
    "for stock in sp500_tickers: \n",
    "    G.add_node(stock) \n",
    "    \n",
    "#add links \n",
    "for i in range(len(sp500_tickers)): \n",
    "    for j in range(i + 1, len(sp500_tickers)):\n",
    "        stock1 = sp500_tickers[i]\n",
    "        stock2 = sp500_tickers[j]\n",
    "        \n",
    "        # Check if the stock symbols are present in the correlation matrix\n",
    "        if stock1 in corr_matrix.index and stock2 in corr_matrix.columns:\n",
    "            correlation_coefficient = corr_matrix.loc[stock1, stock2]\n",
    "            if not np.isnan(correlation_coefficient):\n",
    "                G.add_edge(stock1, stock2, weight=correlation_coefficient)\n",
    "\n",
    "#visualization \n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "# Draw only edges with significant correlation\n",
    "edges = [(source, target) for source, target, data in G.edges(data=True) if abs(data['weight']) > 0.5]\n",
    "nx.draw_networkx_nodes(G, pos, node_size=30)\n",
    "nx.draw_networkx_labels(G, pos, font_size=8)\n",
    "nx.draw_networkx_edges(G, pos, edgelist=edges, edge_color='gray')\n",
    "\n",
    "labels = nx.get_edge_attributes(G, 'weight')\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97870d85-4565-4744-8405-904cc9ca9aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#REF \n",
    "#import pandas as pd \n",
    "#import yfinance as yf \n",
    "\n",
    "#url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "#read tables into PD dataframe \n",
    "#dfs = pd.read_html(url) \n",
    "\n",
    "#get first table (index 0) + first 3 cols \n",
    "#df = dfs[0].iloc[:, :3] \n",
    "#print(df) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
